{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardW=60\n",
    "cardH=114\n",
    "cornerXmin=3\n",
    "cornerXmax=9\n",
    "cornerYmin=2\n",
    "cornerYmax=20\n",
    "\n",
    "# We convert the measures from mm to pixels: multiply by an arbitrary factor 'zoom'\n",
    "# You shouldn't need to change this\n",
    "zoom=4\n",
    "cardW*=zoom\n",
    "cardH*=zoom\n",
    "\n",
    "refCard=np.array([[0,0],[cardW,0],[cardW,cardH],[0,cardH]],dtype=np.float32)\n",
    "refCardRot=np.array([[cardW,0],[cardW,cardH],[0,cardH],[0,0]],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "from glob import glob \n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from shapely.geometry import Polygon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1c', '2c', '3c', '4c', '5c', '6c', '7c', '8c', '9c']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "data_dir=\"data_input\" # Directory that will contain all kinds of data (the data we download and the data we generate)\n",
    "\n",
    "if not os.path.isdir(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "card_suits=['c']\n",
    "card_values=['1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "list_cards = []\n",
    "for suit,value in itertools.product(card_suits, card_values):\n",
    "    list_cards.append('{}{}'.format(value,suit))\n",
    "\n",
    "print(list_cards)\n",
    "\n",
    "# imgW,imgH: dimensions of the generated dataset images \n",
    "imgW=720\n",
    "imgH=720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of the cards from pictures or video "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the alphamask\n",
    "The alphamask has 2 purposes:\n",
    "- clean the border of the detected cards,\n",
    "- make that border transparent. Cards are not perfect rectangles because corners are rounded. We need to make transparent the zone between the real card and its bounding rectangle, otherwise this zone will be visible in the final generated images of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bord_size=3 # bord_size alpha=0\n",
    "alphamask=np.ones((cardH,cardW),dtype=np.uint8)*255\n",
    "cv2.rectangle(alphamask,(0,0),(cardW-1,cardH-1),0,bord_size)\n",
    "cv2.line(alphamask,(bord_size*3,0),(0,bord_size*3),0,bord_size)\n",
    "cv2.line(alphamask,(cardW-bord_size*3,0),(cardW,bord_size*3),0,bord_size)\n",
    "cv2.line(alphamask,(0,cardH-bord_size*3),(bord_size*3,cardH),0,bord_size)\n",
    "cv2.line(alphamask,(cardW-bord_size*3,cardH),(cardW,cardH-bord_size*3),0,bord_size)\n",
    "#plt.figure(figsize=(10,10))\n",
    "#plt.imshow(alphamask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function extract_card \n",
    "Extract from scene image (cv2/bgr) the part corresponding to the card and transforms it \n",
    "to fit into the reference card shape.\n",
    "We suppose here that the user facilitates as much as he can the extraction task by\n",
    "making the scene image simple (one card on uniform backgroung, not too blurry, correct lighting,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varianceOfLaplacian(img):\n",
    "    \"\"\"\n",
    "    Compute the Laplacian of the image and then return the focus\n",
    "    measure, which is simply the variance of the Laplacian\n",
    "    Source: A.Rosebrock, https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "    \"\"\"\n",
    "    return cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "\n",
    "def extract_card (img, output_fn=None, min_focus=120, debug=False):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    imgwarp=None\n",
    "    \n",
    "    # Check the image is not too blurry\n",
    "    focus=varianceOfLaplacian(img)\n",
    "    if focus < min_focus: \n",
    "        if debug: print(\"Focus too low :\", focus)\n",
    "        return False,None\n",
    "    \n",
    "    # Convert in gray color\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Noise-reducing and edge-preserving filter\n",
    "    gray=cv2.bilateralFilter(gray,11,17,17)\n",
    "    \n",
    "    # Edge extraction\n",
    "    edge=cv2.Canny(gray,30,200)\n",
    "    \n",
    "    # Find the contours in the edged image\n",
    "    _,cnts, _ = cv2.findContours(edge.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # We suppose that the contour with largest area corresponds to the contour delimiting the card\n",
    "    cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]\n",
    "    \n",
    "    # We want to check that 'cnt' is the contour of a rectangular shape\n",
    "    # First, determine 'box', the minimum area bounding rectangle of 'cnt'\n",
    "    # Then compare area of 'cnt' and area of 'box'\n",
    "    # Both areas sould be very close\n",
    "    rect=cv2.minAreaRect(cnt)\n",
    "    box=cv2.boxPoints(rect)\n",
    "    box=np.int0(box)\n",
    "    areaCnt=cv2.contourArea(cnt)\n",
    "    areaBox=cv2.contourArea(box)\n",
    "    valid=areaCnt/areaBox>0.95\n",
    "    \n",
    "    if valid:\n",
    "        # We want transform the zone inside the contour into the reference rectangle of dimensions (cardW,cardH)\n",
    "        ((xr,yr),(wr,hr),thetar)=rect\n",
    "        # Determine 'Mp' the transformation that transforms 'box' into the reference rectangle\n",
    "        if wr>hr:\n",
    "            Mp=cv2.getPerspectiveTransform(np.float32(box),refCard)\n",
    "        else:\n",
    "            Mp=cv2.getPerspectiveTransform(np.float32(box),refCardRot)\n",
    "        # Determine the warped image by applying the transformation to the image\n",
    "        imgwarp=cv2.warpPerspective(img,Mp,(cardW,cardH))\n",
    "        # Add alpha layer\n",
    "        imgwarp=cv2.cvtColor(imgwarp,cv2.COLOR_BGR2BGRA)\n",
    "        \n",
    "        # Shape of 'cnt' is (n,1,2), type=int with n = number of points\n",
    "        # We reshape into (1,n,2), type=float32, before feeding to perspectiveTransform\n",
    "        cnta=cnt.reshape(1,-1,2).astype(np.float32)\n",
    "        # Apply the transformation 'Mp' to the contour\n",
    "        cntwarp=cv2.perspectiveTransform(cnta,Mp)\n",
    "        cntwarp=cntwarp.astype(np.int)\n",
    "        \n",
    "        # We build the alpha channel so that we have transparency on the\n",
    "        # external border of the card\n",
    "        # First, initialize alpha channel fully transparent\n",
    "        alphachannel=np.zeros(imgwarp.shape[:2],dtype=np.uint8)\n",
    "        # Then fill in the contour to make opaque this zone of the card \n",
    "        cv2.drawContours(alphachannel,cntwarp,0,255,-1)\n",
    "        \n",
    "        # Apply the alphamask onto the alpha channel to clean it\n",
    "        alphachannel=cv2.bitwise_and(alphachannel,alphamask)\n",
    "        \n",
    "        # Add the alphachannel to the warped image\n",
    "        imgwarp[:,:,3]=alphachannel\n",
    "        \n",
    "        # Save the image to file\n",
    "        if output_fn is not None:\n",
    "            cv2.imwrite(output_fn,imgwarp)\n",
    "        \n",
    "    if debug:\n",
    "        cv2.imshow(\"Gray\",gray)\n",
    "        cv2.imshow(\"Canny\",edge)\n",
    "        edge_bgr=cv2.cvtColor(edge,cv2.COLOR_GRAY2BGR)\n",
    "        cv2.drawContours(edge_bgr,[box],0,(0,0,255),3)\n",
    "        cv2.drawContours(edge_bgr,[cnt],0,(0,255,0),-1)\n",
    "        cv2.imshow(\"Contour with biggest area\",edge_bgr)\n",
    "        if valid:\n",
    "            cv2.imshow(\"Alphachannel\",alphachannel)\n",
    "            cv2.imshow(\"Extracted card\",imgwarp)\n",
    "\n",
    "    return valid,imgwarp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function extract_cards_from_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cards_from_video(video_fn, output_dir=None, keep_ratio=3, min_focus=120, debug=False):\n",
    "    \"\"\"\n",
    "        Extract cards from media file 'video_fn' \n",
    "        If 'output_dir' is specified, the cards are saved in 'output_dir'.\n",
    "        One file per card with a random file name\n",
    "        Because 2 consecutives frames are probably very similar, we don't use every frame of the video, \n",
    "        but only one every 'keep_ratio' frames\n",
    "        \n",
    "        Returns list of extracted images\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(video_fn):\n",
    "        print(f\"Video file {video_fn} does not exist !!!\")\n",
    "        return -1,[]\n",
    "    if output_dir is not None and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    cap=cv2.VideoCapture(video_fn)\n",
    "    a=cv2.VideoCapture(video_fn)\n",
    "    a.set(cv2.CAP_PROP_POS_AVI_RATIO,1)\n",
    "    #print(a.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "    #print(a.get(cv2.CAP_PROP_POS_MSEC))\n",
    "    \n",
    "    frame_nb=0\n",
    "    imgs_list=[]\n",
    "    while True:\n",
    "        ret,img=cap.read()\n",
    "        if not ret: break\n",
    "        # Work on every 'keep_ratio' frames\n",
    "        if frame_nb%keep_ratio==0:\n",
    "            if output_dir is not None:\n",
    "                output_fn=give_me_filename(output_dir,\"png\")\n",
    "            else:\n",
    "                output_fn=None\n",
    "            valid,card_img = extract_card(img,output_fn,min_focus=min_focus,debug=debug)\n",
    "            if debug: \n",
    "                k=cv2.waitKey(1)\n",
    "                if k==27: break\n",
    "            if valid:\n",
    "                imgs_list.append(card_img)\n",
    "        frame_nb+=1\n",
    "    \n",
    "    if debug:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return imgs_list\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Card extraction from all the videos\n",
    "We suppose we have for each card_name (ex: 2d, Kc, Ah) one video file named 'card_name.extension' (ex: 2d.avi, Kc.avi, Ah.avi) in a common directory (ex: data/video). If you use images instead of movies, the script below should work by setting the variable 'extension' below to \"jpg\" or \"png\". \n",
    "The cards from a video, or the card from an image, will be extracted in a subdirectory named 'card_name' placed in the directory 'imgs_dir' (ex: data/cards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted images for 1c : 41\n",
      "Extracted images for 2c : 69\n",
      "Extracted images for 3c : 51\n",
      "Extracted images for 4c : 30\n",
      "Extracted images for 5c : 70\n",
      "Extracted images for 6c : 61\n",
      "Extracted images for 7c : 69\n",
      "Extracted images for 8c : 63\n",
      "Extracted images for 9c : 61\n"
     ]
    }
   ],
   "source": [
    "video_dir=\"data_input/video\"\n",
    "extension=\"mp4\"\n",
    "imgs_dir=\"data_input/cards\"\n",
    "\n",
    "#for suit in card_suits:\n",
    "#    for value in card_values:\n",
    "for card_name in list_cards:        \n",
    "     #   card_name=value+suit\n",
    "        video_fn=os.path.join(video_dir,card_name+\".\"+extension)\n",
    "        output_dir=os.path.join(imgs_dir,card_name)\n",
    "        if not os.path.isdir(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        imgs=extract_cards_from_video(video_fn,output_dir)\n",
    "        print(\"Extracted images for %s : %d\"%(card_name,len(imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb images for 1c : 15\n",
      "Nb images for 2c : 15\n",
      "Nb images for 3c : 15\n",
      "Nb images for 4c : 15\n",
      "Nb images for 5c : 15\n",
      "Nb images for 6c : 15\n",
      "Nb images for 7c : 15\n",
      "Nb images for 8c : 15\n",
      "Nb images for 9c : 15\n",
      "Saved in : data_input/cards.pck\n"
     ]
    }
   ],
   "source": [
    "imgs_dir=\"data_input/cards\"\n",
    "\n",
    "num_images_per_card = 15\n",
    "\n",
    "import random\n",
    "cards={}\n",
    "for suit in card_suits:\n",
    "    for value in card_values:\n",
    "        card_name=value+suit        \n",
    "        card_dir=os.path.join(imgs_dir,card_name)\n",
    "        if not os.path.isdir(card_dir):\n",
    "            print(f\"!!! {card_dir} does not exist !!!\")\n",
    "            continue\n",
    "        cards[card_name]=[]\n",
    "        for f in random.sample(glob(card_dir+\"/*.png\"), num_images_per_card):\n",
    "        #for f in glob(card_dir+\"/*.png\"):\n",
    "            img=cv2.imread(f,cv2.IMREAD_UNCHANGED)\n",
    "            # We store the image in \"rgb\" format (we don't need opencv anymore)\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGRA2RGBA)\n",
    "          #  print(img.shape)\n",
    "            cards[card_name].append((img,1,1))\n",
    "        print(f\"Nb images for {card_name} : {len(cards[card_name])}\")\n",
    "\n",
    "        \n",
    "cards_pck_fn = data_dir + \"/cards.pck\"\n",
    "print(\"Saved in :\",cards_pck_fn)\n",
    "pickle.dump(cards,open(cards_pck_fn,'wb'))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
